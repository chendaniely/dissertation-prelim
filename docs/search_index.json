[["index.html", "Prelim Prelim a la NIH R01 Summary Statement", " Prelim Prelim a la NIH R01 Daniel Chen 2021-02-02 Summary Statement Aim 1: Identify learner personas in the biomedical sciences by creating and validating learner self-assessment surveys. 1.1: Learner self-assessment survey asking questions about prior programming, statistics, and data knowledge will be used to create learner personas. 1.2: Validate learner self-assessment survey. 1.3: Personas will encompass a students prior knowledge using survey data. General background, perception of needs, and special considerations will be added to make each learner persona a complete character. Aim 2: Create an effective data science for biomedical science curriculum based on best education and pedagogy practices. 2.1: Learning objectives focused around core data literacy principles in the data science pipeline will be used for each lesson module. 2.2 Lesson content follow best educational and pedagogical best practices. 2.3 Assess the effectiveness of learning materials. Aim 3: Assess the effectiveness of formative assessments in learning learning objectives. 3.1: Implement an experiment for conduting formative and summative assessment question types. 3.2: Assess the effectiveness of targeted feedback in autograding systems used in formative and summative feedback. "],["significance.html", "Chapter 1 Significance 1.1 Importance of the problem to be addressed 1.2 Rigor of Prior Research Supporting the Aims 1.3 Significance of the Expected Research Contribution", " Chapter 1 Significance 1.1 Importance of the problem to be addressed 2,314 exabytes of new medical data is projected to be produced in 2020 (Stewart 2020). The sheer volume of data requires the understanding, accessing, managing, and interpreting of data across researchers, clinicians, and patients (Institute of Medicine (US) Roundtable on Value &amp; Science-Driven Health Care 2010). By democratizing data science skills for clinicians, they will be able to better understand their patient population, better communicate with research teams to improve the outcomes of patients, and be better advocates for their patients. However, existing data science learning materials in the medical and biomedical sciences lack one of the following features: (1) is community oriented, (2) has an open creative commons license, (3) is maintained, (4) is accessible, and (5) follows education and pedagogy best practices to target learning objectives. These are features that would modernize the biomedical data-resource ecosystem, promote Findable, Accessible, Interoperable, and Reusable (FAIR) principles, and enhance the the data science and research workforce in the biomedical sciences. The Health Information Technology for Economic and Clinical Health (HITECH) Act included the concept of Electronic Health Records - Meaningful Use (EHR-MU) which incentivised all medical records to be electronic by 2014. Currently, in 2020 more than 89% of all hospitals have implemented an EHR system. While EHR systems have their own data challenges, the influx of electronic data has called for changes in how clinicians undergo training to meet the challenges of evidenced-based medicine using these data. By contextualizing and democratizing the data science skills for clinicians we can provide them more capacity explore and make better use of the data. Additionally, by empowering the people using and working with better data literacy and data science skills, we can build the workforce needed to better use and collect the data we need to innovate and progress health care. Programming courses are generally considered difficult with high dropout rates. Motivation and mindset are some of the integral roles in learning programming and building life-long learners. A backward design approach using learner personas for creating lessons help keep teaching focused on objectives and help cater the needs of the learner to the overall learning objectives. Data science tools are built around tidy data principles, a core data literacy topic describing how the rows and columns of a data set need to be specified for analysis. Once the lessons are created, it can be freely shared (e.g., using a CC-0 creative commons license) and improved upon, but also has the flexibility to be adapted to individual instructor needs. We focus the materials around tidy data principles because the data science process requires a tidy dataset to begin the cycle of understanding the data before results can be communicated (Figure 1.1). Figure 1.1: Figure taken from the R for Data Science book (Wickham and Grolemund 2016). Unfortunately, the data science process is not this linear, and requires many smaller feedback loops (Figure 1.2). Notably, data science products usually end up with some decision or action that will affect the world. This makes each step of the data science process influential to the final set of decisions. Notably, each step of the data science pipeline is a data set, and the data literacy skills needed to process and work with the data in each step is paramount to the final results. Figure 1.2: Steps in a data science pipeline showing the mini feedback loops that affect the final decision which will have some consequence in the world (Chen 2020). This proposal seeks to address the following knowledge gaps in the literature: (1) There are no formal learner personas for the biomedical community and the assessment tools to identify and create learner personas do not exist. (2) Data science learning materials for the biomedical sciences lack community oriented, open, and maintained lessons targeting learner persona needs grounded in pedagogical practices and theory. (3) While we know a lot about the teaching and pedagogy of computer science education, less is known about data literacy education, and almost nothing is known about data science education. 1.2 Rigor of Prior Research Supporting the Aims Aim 1: Identify learner personas in the biomedical sciences by creating and validating learner self-assessment surveys. Personas are detailed fictional characters based on well-understood and highly specified data to facilitate user-centered design (Pruitt and Adlin 2006; Zagallo et al. 2019). Learner personas encompass a learners general background, prior relevant knowledge, perception of needs, and special considerations (Wilson 2019). These personas can be used along with a backwards lesson design method to keep teaching focused on learning objectives, and keep assessment materials within the scope of the learning materials (Wilson 2019). In order to identify the learner personas, we adapted questions from The Carpentries (insert citations), How Learning Works (Ambrose et al. 2010), and Teaching Tech Together (Wilson 2019) and focused on 3 knowledge domains: programming knowledge, data knowledge, and statistics knowledge. These the questions were sent out to list serves and results can be clustered to identify personas using hierarchical clustering (Zagallo et al. 2019). The personas created can help future educators in the biomedical sciences teaching data science skills focus their content so they are relevant to the population and address their needs. The survey and persona clustering methodology can be adapted and utilized to create data science materials for other professional domains. Figure 1.3: Shows the 4 clusters created from the hierarchical clustering using euclidean distance and wards. These cluster assignments were then combined with the survey responses to identify the personas. From left to right: experts, clinicians, students, and academics. Figure 1.3 shows the persona clustering. The identified clusters were combined with the original survey data to fill in the each personas prior relevant knowledge and background. The perception of needs and special considerations were created to make each persona complete but not based on survey data. A future qualitative study would be needed to get a more accurate background, need, and special considerations for the personas (Zagallo et al. 2019). The survey also went though a validation phase, looking at Principle Component Analysis (PCA) and Exploratory Factor Analysis (EFA) results. The EFA results were also used to simplify he survey down to 3 question, one for each of the knowledge domains. Aim 2: Create an effective data science for biomedical science curriculum based on best education and pedagogy practices. A backwards design approach was used to create the data science curriculum for the biomedical sciences. This puts the learning objectives, formative and summative assessment questions at the forefront of the lesson material to keep them focused and in the scope of the lesson (Wilson 2019). Learners who want to learn how to perform data analysis, typically, also need to learn data literacy skills to learn how to obtain and manipulate data (Milo 2005). We use tidy data principles as the guiding concept of data literacy (Wickham 2014) to focus our learning objectives. Best practices on education and pedagogy dictate we create small focused lessons and reinforce the learning objectives by creating a series of formative assessments (Wilson 2019). In order to test the content and effectiveness of the materials and its learning objectives, we use a series of pre-workshop and post-workshop surveys to determine learners confidence in the learning objectives (carpentries citation). Figure 1.4: Shows the changes from the pre-wokshop and post-workshop responses. The numbers show the differences from the pre-workshop counts, from the post-workshop counts. White (0) means there was a net 0 difference between reponses. Blue represents where more responses went to after the workshop and red represents the number of people who migrated from a particular response after the workshop. A long-term survey will be sent out to respondents to see how their confidence with the same set of learning objectives have changed over 6 months, to see how learners may have retained and built on the the knowledge from the workshop. There is a final summative assessment question in both the post-workshop and long-term survey. The surveys and learning materials will serve as the first set of community oriented, open with a creative commons license, accessible, and follows best pedagogical practices. Maintainability needs to be accessed over loger periods of time, but organizations like the carpentries provide a community and mechanism where these materials can be migrated to after the initial curriculum assessment is complete to find other lesson maintainers in their incubator and lab community lessons. Aim 3: Assess the effectiveness of formative assessments in learning learning objectives Formative assessments are a pedagogical tool instructors use to identify learners misconceptions (Wilson 2019). In order to reduce the cognitive load on the learners, various types of assessment questions can be used. Parsons problems take a block of solution code, scramble the order of the lines, and ask the learner to assemble to code back into the correct execution order. Faded examples provide working code snippets with some amount of the code blanked out. Parsons problems allow the learner to focus on the overall steps and flow of the thought process, and faded examples focus the learners attention to a specific part of the code. Both provide some kind of scaffolding mechanism for the student, so they are not writing code from scratch. These assessments will look for time to complete and solution correctness as a measure of meeting the learning objectives. It will also be the first set of data science specific formative assessments focused on data literacy topics, and not basic programming concepts in the computer science literature. By keeping both the learning materials from Aim 2, and the assessment tools focused on learning objectives, we hope that these will lead to better learning outcomes in the learners by looking at a final summative assessment question (Figure 1.5) Figure 1.5: Shows the responses to a summative assessment question at the end of the workshop. The question asked the learners about a learners comfort in loading a tabulated dataset, tidy it up, and perform a small analysis. 1.3 Significance of the Expected Research Contribution Upon successful completion of the proposed studies, we expect our contribution to be a framework of how to create domain specific data science learning materials. The personas from the study can be used when teaching data science to new learners in the medical and biomedcal sciences. The surveys used to create the personas can be used to other domains which can inform instructors about their learners. In addition, we are performing one of the few studies that look in to how students learn in a data literacy and data science context, not in a computer science context. This contribution is expected to be significant because of the growing need in the workforce for data science education, and this study not only creates data science learning materials following best education and petagogical practices, but also creates a curriculum in the biomedical sciences domain and creates the tools and framework for expanding the content to other domains. We also assess the effectiveness of formative assessment questions in learning the data science and data literacy contexts. References "],["innovation.html", "Chapter 2 Innovation", " Chapter 2 Innovation Our work creates and validates a survey that can be used in the biomedical science to create learner personas. Weve adapted survey questions from other educators to create 4 surveys: self-assessment, pre-workshop, post-workshop, and long-term workshop. These surveys are general enough to capture data literacy, programming, and statistics knowledge, while also being domain specific and flexible to be adapted to other domains. Weve also validated these surveys so they can be used for further studies and as a tool for educators, and lays the groundwork for more survey external validation to identify data science learner personas. The surveys have been used to create learner personas which are the first set of published personas for learners in the biomedical sciences, and the methods used can be used to create learner personas for other domains and other subgroups of data science (e.g., statistics literacy, data management literacy) The learning materials we have created are the only ones that link the data literacy skills to the overall data science process. Many books around data science mainly focus on the actual model fitting and evaluation of the data science process. Other books on data processing go through too many data processing details without having meaningful payoffs. The content we have created using a backwards design approach always frames key data science steps in the context of data literacy and data processing pipelines. This creates a more holistic set of topics that are taught at the point of need, while highlighting avenues for further learning. In addition, the materials created are one of the few that are community oriented, has a creative commons license, accessible, and follows pedagogical best practices that clearly displays target audience and learning objectives. Our experiments will teach us more about learning data science and data literacy skills, not simply programming and computer science concepts. A lot of literature around computer science education is focused on the programming and topics used in computer science classes. The formative question types used in computer science education informs the types of questions used in data literacy and data science, however, little is known about what formative question topics inform learning objectives in data science curriculum. "],["approach.html", "Chapter 3 Approach 3.1 Human Subject Research 3.2 Introduction 3.3 Hypothesis 3.4 Experimental Design", " Chapter 3 Approach 3.1 Human Subject Research We have an IRB (#20-537) that outlines the minimal risk from the survey participants, and have a data plan for storage, anonymization, and sharing. 3.2 Introduction While there is a lot of literature and studies on computer science education, very little is known about data literacy education, and even less on data science education. Since data science skills inherently involve programming, there are synergies between the educational and pedadogical approach to teaching data science, however, little is known about what are key concepts and learning objectives that need to be taught, and the effectiveness of those learning objectives. Our goal is to Create community-oriented, open, maintained, and focused data science learning materials for the medical and biomedical sciences. To this end, in Aim 1, we lay the ground work for understanding potential learners by identifying and creating learner personas, fictional characters that represent a typical type of learner, by creating and validating a set of self-assessment surveys. In Aims 2 and 3, we create and assess the effectiveness of the learning materials, the workshop that teaches the materials, and the implementation of formative and summative assessment questions to see if learning objectives are met. Our long-term goal is to bridge the skills gap between medical practitioners and domain experts in the biomedical sciences with the analysts, researchers, and data scientists to make better use of data (storage, FAIR, stewardship) in data science teams by creating and bolstering a computational community of practice that can enhance workforce development, modernize the data ecosystem, work with data science tools for sustainable and open science. 3.3 Hypothesis Data science tools are built around inputs that are defined by tidy data principles. Spreadsheet programs make it easy to treat data sets as a visualization, which make the data less flexible for multiple uses. It is possible programming may not be incorporated by learners, but these materials may help curate better datasets that can be used in data science teams. Our central hypothesis is that learning materials with an eye towards the learner and tidy data principles is an effective way to teach the data science and data literacy skills that will help learners incorporate programming and data science skills from their spreadsheet workflows. To address these critical gaps in knowledge, we will create a set of surveys that will inform us of the potential learners and assess the effectiveness of the learning materials. Lesson efficacy will be tested against learning objectives. 3.4 Experimental Design Aim 1: Identify learner personas in the biomedical sciences by creating and validating learner self-assessment surveys Assessing the prior knowledge of potential learners in the medical and biomedical sciences who are interested in learning data science skills by creating a learner self-assessment where participants rate their own comfort in data, statistics, and programming skills. Working Hypothesis We hypothesize that learners will fall across the 3 main groups of the Dreyfus model of skill acquisition: novice, intermediate, and expert. These groups will be distinguishable based on their own comfort in 3 domains of data science (data, programming, and statistics knowledge), To test this we will create a learner self-assessment survey. The survey will cover data, programming, and statistics knowledge and will have at least 2 questions asking about the same underlying concept for internal consistency. Results from the survey along with demographic information will be combined to create the personas. These personas will be used to inform the learning objectives for lesson materials. Preliminary Data for Aim 1 In preliminary studies, we found that we were able to cluster the respondents into 4 clusters using hierarchical clustering with euclidean distance and Wards method. We then combined these clusters with the occupation question to come up with the 4 learner personas: clinicians (novice), academics (intermediate), students (intermediate), and programmers (experts). 1.1: Learner self-assessment survey asking questions about prior programming, statistics, and data knowledge will be used to create learner personas We will send out self-assessment surveys to various medical and biomedical groups around the Virginia Tech campus. We collected preliminary data over the summer of 2020 and had 51 participants consented to the survey. Figure ?? shows the grouped distribution of responses to the occupation demographic question (this is a select-all-that-apply question). In general we found that the overall group has low programming skills with basic data analysis skills primarily using Excel. IN general, they do not understand how data pipelines are created, and do not now how data can be processed into different shapes for analysis. These results are summarized in Figures ??, ??, ??, ??, ??, and ??. The survey we created also asked a summary likert scale table of questions (Figure ??). These results confirm the overall findings where respondents typically do not use a programming language in their work, and are indifferent towards programming in doing analysis. They did report that having access to the original raw data is important to repeat an analysis. This let us conclude that there is a lack of knowledge in the data literacy fundamentals where data can be transformed from user-friendly data curation formats to analysis-friendly formats in multiple pipelineing steps. 1.2: Validate learner self-assessment survey The survey was designed with the questions in duplicate for internal validity, i.e., each construct was asked in 2 separate questions. Figure ?? shows how half of the questions (8 out of 16) account for more than 90% of the variance in PCA, with the first component accounting for 46% and 3 components accounting for 68%. Since our survey was designed using 3 main constructs: programming, statistics, and data knowledge, these results show that the survey was well designed and has internal consistency among the respondents. We also conducted an exploratory factor analysis on our preliminary data, and used 3 factors, one for each latent variable. The question loadings also followed the constructs in the survey, suggesting the validity of the survey. We would need to expand the survey to more participants to show its external validity. Given the preliminary data, we propose to perform more validation checks by increasing the sample size. We will be able to calculate the Cohens kappa coefficient to measure inter-rater reliability and the larger sample size will improve the external validity of the survey. 1.3: Personas will encompass a students prior knowledge using survey data. General background, perception of needs, and special considerations will be added to make each learner persona a complete character We used hierarchical clustering with euclidean distance and wards method on our preliminary data to create the learner personas (Figure ??). This approach is validated from preliminary results showing the 4 learner personas from our data. We combined these groupings back with the survey occupation demographics to create the relevant prior knowledge portion of learner personas. Our preliminary data gave us 4 personas that map on to the different stages of the Dreyfus model of skill acquisition: clinicians (novice), academics (intermediate), students (intermediate), and programmers (experts). Anticipated results and their impact Preliminary results show that we are able to validate use the learner self-assessment survey and use the survey results to create learner personas. This gives us an overview of the audience we would potentially teach in the medical and biomedical sciences. Since the final step of persona creation combines the demographic information, the base survey questions can be used across other domains, not just the one we are studying. This potentially gives us a tool to accurately gauge data science learners to better create learning materials for their needs. Potential pitfalls, alternative approaches, and future directions The data collection process is based on surveys. This inherenctly means we will have reporting and response bias. The demographic breakdown in our learner self-assessment was fairly diverse (Figure ??), but our preliminary data was only collected from Virginia Tech students and faculty from biomedcially relevant listservs. Future directions would include increasing the survey pool to get a better representation of potential learners. A larger survey pool would also help with the survey validation by potentially surveying a more diverse population and also increase our N for the analysis. Aim 2: Create an effective data science for biomedical science curriculum based on best education and pedagogy practices Working Hypothesis We hypothesize that a data science curriculum focused around data literacy principles from working with spreadsheet data will be the most relevant to our learners. We also hypothesize that the learning objectives we create will give the learners confidence in performing their own data analysis after going through the materials. By catering to the learners needs, and teaching the data literacy fundamentals, learners will be more motivated to continue learning on their own. To test this hypothesis we will create a set of pre-workshop, post-workshop, and long-term workshop surveys. Since this is an observational study, we will use the learners confidence on their ability to accomplish a task as a proxy for meeting learning objectives. There will be a set of self assessment and learning objective tasks that will be asked across all surveys to measure differences in response longitudinally. Preliminary Data for Aim 2 A data science curriculum based on learner personas was created and used to teach a set of workshops. Preliminary data collected before and after the workshop compare a learners confidence of meeting learning objectives, and show that the learners are more confident in their skills and learning objectives (Figure ?? and ??) 2.1: Learning objectives focused around core data literacy principles in the data science pipeline will be used for each lesson module In this subaim we will create a data science curriculum that ties together data literacy and data management pipelines with the skills used in data science. Our preliminary learner personas guided us to use spreadsheet programs (e.g., Excel, LibreOffice, Google Sheets, etc) as the first lesson module to orient the learners and use tidy data principles as the underlying theme to transform data. Preliminary data and a survey of available lesson materials show that there is a gap in available teaching materials that link data literacy concepts of data management and processing with other steps in the data science process. 2.2 Lesson content follow best educational and pedagogical best practices The lesson materials created will follow the best educational and pedagogical best practices for learning programming. To account for the different learning styles, a book and slide deck format of the materials will be created. Workshops from the materials will also be recorded with live captioning and uploaded in the public domain (e.g., YouTube). Learning objectives following Blooms taxamony will be created for each lesson module. Previous studies have shown that programming concepts should be in shorter blocks of time, with small formative assessment exercises used to assess learning objectives. We are working on lesson materials that can be roughly taught in 45 to 50 minute increments, leaving time for a break and formative assessment. This time block also coincides with the typical period of a classroom session so the materials can be adapted for a broader educational purpose. 2.3 Assess the effectiveness of learning materials In this subaim, we will assess how effective the lesson materials and its learning objectives are by comparing results from a pre-workshop and post-workshop survey. Survey participants will have a unique identifier that can be used to track individual differences and be aggregated to look at the overall effect changes before and after the workshop. Preliminary data shows that learners confidence in various tasks and learning objectives do improve after the workshop. A long-term survey will be sent out to workshop participants to see retention of learning objectives, if learners found the workshop useful, and if learners have continued to learn and work on their own projects. Anticipated results and their impact We anticipate that a lesson curriculum that incorporates existing tools and prior knowledge of spreadsheets will help learners fill in gaps of their data literacy mental model when working with data in data science projects. By focusing on data literacy concepts, we are building a curriculum that promotes FAIR principles. This aim will create a tested learning curriculum that can be adapted into many teaching and learning formats. The book can be done as supplemental reading or as self-paced reading, the slides provide major points that can be used in a lecture or presentation, and recordings are provided to learners either as a reference or material for new learners who cannot attend a live workshop setting. These materials lay the groundwork for a community-oriented, open, accessible, and pedagogically sound curriculum that can be used to enhance the data science and research workforce in the biomedical sciences and adapted to other domains. Potential pitfalls, alternative approaches, and future directions Our preliminary data shows more reporting bias than our learner self-assessment survey. Most of the respondents from the workshop surveys are students, and not from the other occupation groups. This problem can be remedied by conducting more workshops to collect more data which may offset the bias. Our surveys mainly measure the learners confidence towards a learning objective as a proxy for a summative assessment. These results are self-reported and may show response bias. Aim 3: Assess the effectiveness of formative assessments in learning learning objectives Working Hypothesis We hypothesize that formative assessments with targeted and informative feedback about incorrect solutions, will allow learners to complete formative and summative assessment questions with a higher rate of success. We also hypothesize that guiding learners with parsons problems and faded in formative feedback exercises will help them solve summative feedback questions faster. Preliminary Data for Aim 3 Our hypothesis is based on computer science education literature that uses different question types for formative assessment questions to aid in learning content. These question types (faded examples and parsons problems) are used in lieu of a blank box where the learners write code from scratch becuase it lowers the cognitive load of the learners and allows them to focus on the key aspect off the coding exercise, instead of wresting with the syntax of the code. 3.1: Implement an experiment for conducting formative and summative assessment question types The shinysurveys R package (https://github.com/jdtrat/shinysurveys) provides the framework needed to create and administer an experimental study that can be used to collect response data from user submitted code. It leverages the learnr R package that allows instructors to create lesson materials with an input field that can execute code. The gradethis library can be used to check R and Python code for the correct result to provide feedback to the student. gradethis also has the ability too check the syntax of the code itself to point to an exact part of the code that is incorrect, instead of giving a programming error or non-meaningful incorrect message. shinysurveys can be used in conjunction with the tools and techniques from Data Science in a Box (https://datasciencebox.org/) to collect the responses from the student for analysis using the learnrhash library (https://github.com/rundel/learnrhash/). 3.2: Assess the effectiveness of targeted feedback in autograding systems used in formative and summative feedback In this aim we hope to show an improvement in the success rate of assessment questions when targeted feedback about the incorrect solution is given by the learner. We know feedback is an important step in the learning process, but it is not possible to give real-time feedback during many assessment questions, especially when teaching at scale. We hope to take the results from our implementation of shinysurveys and Data Science in a Box to collect learner assessment performance and compare the differences between learners who are givin differnt types of assessment questions from those who are simply given an empty box to type code with and without informative feedback from the autograder. Anticipated results and their impact We are expecting to see an improvement in speed and correct responses in students final summative assessment when they are givien who are given question types other than an empty text box in the formative assessment. While these question types are used in computer science education literature, these techniques have not been studied yet to show whether adding the additional cognitive load of completing a data related task helps with learning the materials. We anticipate that these results will give future educators the types of questions that can be used for foramtive assessments when teaching. Potential pitfalls, alternative approaches, and future directions Trying to find the correct population of participants to use in this study will be challenging. Since the study will aim to only teach a single portion of the overall lesson materials, its possible that the amount of information used for this aim will be either too simple or too complex for participants given the time constraints. If that is the case, we may resort to only looking at the amount of time to complete a solution, rather than comparing if the different groups are answering the question correctly. This aim will provide the basis of incorporating a formative and summative assessment system that can be used in a live teaching enviornment so the instrcutor can get feedback about topics and concepts that the learners are grasping. "],["timeline.html", "Chapter 4 Timeline", " Chapter 4 Timeline "],["appendix.html", "Chapter 5 Appendix", " Chapter 5 Appendix "],["references.html", "References", " References Ambrose, Susan A, Michael W Bridges, Michele DiPietro, Marsha C Lovett, and Marie K Norman. 2010. How Learning Works: Seven Research-Based Principles for Smart Teaching. John Wiley &amp; Sons. Chen, Daniel. 2020. Data Science Figure. December 2020. https://github.com/chendaniely/data_science-figure. Institute of Medicine (US) Roundtable on Value &amp; Science-Driven Health Care. 2010. Clinical Data as the Basic Staple of the Learning Health System. In Clinical Data as the Basic Staple of Health Learning: Creating and Protecting a Public Good: Workshop Summary. National Academies Press (US). https://www.ncbi.nlm.nih.gov/books/NBK54306/. Milo, Shields. 2005. Information Literacy, Statistical Literacy, Data Literacy. IASSIST Quarterly 28 (2-3): 66. Pruitt, John, and Tamara Adlin. 2006. The Persona Lifecycle: Keeping People in Mind Throughout Product Design. 1st edition. Amsterdam ; Boston: Morgan Kaufmann. Stewart, Conor. 2020. Healthcare Data Volume Globally 2020 Forecast. Statista. September 24, 2020. https://www.statista.com/statistics/1037970/global-healthcare-data-volume/. Wickham, Hadley. 2014. Tidy Data. Journal of Statistical Software 59 (1, 1): 123. https://doi.org/10.18637/jss.v059.i10. Wickham, Hadley, and Garrett Grolemund. 2016. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. OReilly Media. https://r4ds.had.co.nz/. Wilson, Greg. 2019. Teaching Tech Together: How to Make Your Lessons Work and Build a Teaching Community Around Them. CRC Press. Zagallo, Patricia, Jill McCourt, Robert Idsardi, Michelle K Smith, Mark Urban-Lurain, Tessa C Andrews, Kevin Haudek, et al. 2019. Through the Eyes of Faculty: Using Personas as a Tool for Learner-Centered Professional Development. CBELife Sciences Education 18 (4): ar62. "]]
